{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99bd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import ray\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46be8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 01:15:45,064\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.3</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.3', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:60695', 'raylet_socket_name': 'tcp://127.0.0.1:62467', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\usuario\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-11-23_01-15-43_551752_29012', 'metrics_export_port': 59885, 'gcs_address': '127.0.0.1:62139', 'address': '127.0.0.1:62139', 'dashboard_agent_listen_port': 52365, 'node_id': '744b50d319b63e0a0636ccf0008cd5ec08115ea6598d5a84c4477b40'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce91c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "train_path = \"CASIA_faceAntisp/train_release\"\n",
    "test_path = \"CASIA_faceAntisp/test_release\"\n",
    "\n",
    "dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda126f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self , num_classes=10):\n",
    "    super(CNN, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=2) ,\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "      # nn.Dropout(0.25))\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2) ,\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "      # nn.Dropout(0.25))\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=3) ,\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "      # nn.Dropout(0.25))\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(64, 128, kernel_size=11, stride=1, padding=5) ,\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "      # nn.Dropout(0.25))\n",
    "    self.fc = nn.Linear(8192 , num_classes)\n",
    "    \n",
    "  def forward(self , x):\n",
    "    # print(\"Entro layer 1\")\n",
    "    out = self.layer1(x)\n",
    "    # print(\"Layer 1 Shape: \", out.shape)\n",
    "    out = self.layer2(out)\n",
    "    # print(\"Layer 2 Shape: \", out.shape)\n",
    "    # print(\"Paso layer 2\")\n",
    "    out = self.layer3(out)\n",
    "    # print(\"Layer 3 Shape: \", out.shape)\n",
    "    # print(\"Paso layer 3\")\n",
    "    out = self.layer4(out)\n",
    "    # print(\"Layer 4 Shape: \", out.shape)\n",
    "    # print(\"Paso layer 4\")\n",
    "    out = out.reshape(out.size(0) , -1)\n",
    "    # print(\"Reshape Shape: \", out.shape)\n",
    "    # print(\"Reshapeo\")\n",
    "    out = self.fc(out)\n",
    "    # print(\"FC Shape: \", out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b67974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ray.remote\n",
    "def get_training_subject(path, samples_per_video):\n",
    "    real_videos = ['1.avi', '2.avi', 'HR_1.avi', 'HR_4.avi']\n",
    "    subject = []\n",
    "    target = []\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    for dir in os.listdir(os.path.join(path)):\n",
    "        cap = cv2.VideoCapture(os.path.join(path, dir))\n",
    "        resampling_rate = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / samples_per_video)\n",
    "        count = 0\n",
    "        failed = False\n",
    "        crops = []\n",
    "        entry = []\n",
    "        while cap.isOpened():\n",
    "            success, img = cap.read()\n",
    "            if failed or success and count%resampling_rate == 0:\n",
    "                faces = face_cascade.detectMultiScale(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 1.1, 4)\n",
    "                if len(faces) != 1:\n",
    "                    failed = True\n",
    "                    continue\n",
    "                (x, y, w, h) = faces[0]\n",
    "                entry.append(cv2.resize(img[y:y+h,x:x+w], dsize=(dim,dim)))\n",
    "                failed = False\n",
    "            else:\n",
    "                break\n",
    "            count += 1\n",
    "        subject.append(torch.Tensor(entry[0]))\n",
    "        target.append(1 if dir in real_videos else 0)\n",
    "    return subject, target\n",
    "\n",
    "def read_training_files(path, samples_per_video=16):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        f, t = get_training_subject(os.path.join(path,person), samples_per_video)\n",
    "        features += f\n",
    "        targets += t\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4139d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:25<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "train_features, train_targets = read_training_files(train_path, samples_per_video=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "332d10a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:06<03:06,  6.42s/it]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29012/2528499101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_training_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_per_video\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29012/3336248014.py\u001b[0m in \u001b[0;36mread_training_files\u001b[1;34m(path, samples_per_video)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mperson\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_training_subject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_per_video\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29012/3336248014.py\u001b[0m in \u001b[0;36mget_training_subject\u001b[1;34m(path, samples_per_video)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mresampling_rate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "test_features, test_targets = read_training_files(test_path, samples_per_video=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5985a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.stack(train_features)\n",
    "train_features = train_features.permute(0, 3, 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac38727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 3, 128, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c50324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = torch.Tensor(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fb555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2525424",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0063b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs):\n",
    "  # train the model\n",
    "  list_loss= []\n",
    "  avg_list_loss = []\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    images = train_features.to(device)\n",
    "    labels = train_targets.type(torch.LongTensor).to(device)\n",
    "    output = model(images)\n",
    "    # print(output)\n",
    "    loss   = loss_fn(output, labels)\n",
    "    # change the params\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    list_loss.append(loss.item())\n",
    "            \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                  .format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    avg_list_loss.append(np.mean(list_loss))\n",
    "\n",
    "    list_loss = []\n",
    "    \n",
    "  print('Finished Training Trainset')\n",
    "  return avg_list_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1b27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae74773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.8388\n",
      "Epoch [2/100], Loss: 5.2006\n",
      "Epoch [3/100], Loss: 1.2402\n",
      "Epoch [4/100], Loss: 0.9675\n",
      "Epoch [5/100], Loss: 0.7529\n",
      "Epoch [6/100], Loss: 0.7825\n",
      "Epoch [7/100], Loss: 0.7412\n",
      "Epoch [8/100], Loss: 0.6092\n",
      "Epoch [9/100], Loss: 0.5641\n",
      "Epoch [10/100], Loss: 0.5776\n",
      "Epoch [11/100], Loss: 0.5712\n",
      "Epoch [12/100], Loss: 0.5468\n",
      "Epoch [13/100], Loss: 0.5138\n",
      "Epoch [14/100], Loss: 0.4821\n",
      "Epoch [15/100], Loss: 0.4590\n",
      "Epoch [16/100], Loss: 0.4604\n",
      "Epoch [17/100], Loss: 0.4744\n",
      "Epoch [18/100], Loss: 0.4625\n",
      "Epoch [19/100], Loss: 0.4305\n",
      "Epoch [20/100], Loss: 0.4189\n",
      "Epoch [21/100], Loss: 0.4245\n",
      "Epoch [22/100], Loss: 0.4197\n",
      "Epoch [23/100], Loss: 0.4104\n",
      "Epoch [24/100], Loss: 0.4010\n",
      "Epoch [25/100], Loss: 0.3912\n",
      "Epoch [26/100], Loss: 0.3809\n",
      "Epoch [27/100], Loss: 0.3744\n",
      "Epoch [28/100], Loss: 0.3705\n",
      "Epoch [29/100], Loss: 0.3643\n",
      "Epoch [30/100], Loss: 0.3554\n",
      "Epoch [31/100], Loss: 0.3462\n",
      "Epoch [32/100], Loss: 0.3395\n",
      "Epoch [33/100], Loss: 0.3341\n",
      "Epoch [34/100], Loss: 0.3268\n",
      "Epoch [35/100], Loss: 0.3164\n",
      "Epoch [36/100], Loss: 0.3050\n",
      "Epoch [37/100], Loss: 0.2958\n",
      "Epoch [38/100], Loss: 0.2883\n",
      "Epoch [39/100], Loss: 0.2801\n",
      "Epoch [40/100], Loss: 0.2717\n",
      "Epoch [41/100], Loss: 0.2622\n",
      "Epoch [42/100], Loss: 0.2510\n",
      "Epoch [43/100], Loss: 0.2391\n",
      "Epoch [44/100], Loss: 0.2280\n",
      "Epoch [45/100], Loss: 0.2183\n",
      "Epoch [46/100], Loss: 0.2084\n",
      "Epoch [47/100], Loss: 0.1965\n",
      "Epoch [48/100], Loss: 0.1841\n",
      "Epoch [49/100], Loss: 0.1745\n",
      "Epoch [50/100], Loss: 0.1684\n",
      "Epoch [51/100], Loss: 0.1617\n",
      "Epoch [52/100], Loss: 0.1540\n",
      "Epoch [53/100], Loss: 0.1477\n",
      "Epoch [54/100], Loss: 0.1414\n",
      "Epoch [55/100], Loss: 0.1357\n",
      "Epoch [56/100], Loss: 0.1309\n",
      "Epoch [57/100], Loss: 0.1248\n",
      "Epoch [58/100], Loss: 0.1201\n",
      "Epoch [59/100], Loss: 0.1147\n",
      "Epoch [60/100], Loss: 0.1100\n",
      "Epoch [61/100], Loss: 0.1053\n",
      "Epoch [62/100], Loss: 0.1012\n",
      "Epoch [63/100], Loss: 0.0972\n",
      "Epoch [64/100], Loss: 0.0935\n",
      "Epoch [65/100], Loss: 0.0893\n",
      "Epoch [66/100], Loss: 0.0858\n",
      "Epoch [67/100], Loss: 0.0818\n",
      "Epoch [68/100], Loss: 0.0786\n",
      "Epoch [69/100], Loss: 0.0749\n",
      "Epoch [70/100], Loss: 0.0717\n",
      "Epoch [71/100], Loss: 0.0678\n",
      "Epoch [72/100], Loss: 0.0644\n",
      "Epoch [73/100], Loss: 0.0607\n",
      "Epoch [74/100], Loss: 0.0575\n",
      "Epoch [75/100], Loss: 0.0544\n",
      "Epoch [76/100], Loss: 0.0512\n",
      "Epoch [77/100], Loss: 0.0485\n",
      "Epoch [78/100], Loss: 0.0455\n",
      "Epoch [79/100], Loss: 0.0430\n",
      "Epoch [80/100], Loss: 0.0404\n",
      "Epoch [81/100], Loss: 0.0380\n",
      "Epoch [82/100], Loss: 0.0356\n",
      "Epoch [83/100], Loss: 0.0332\n",
      "Epoch [84/100], Loss: 0.0311\n",
      "Epoch [85/100], Loss: 0.0289\n",
      "Epoch [86/100], Loss: 0.0270\n",
      "Epoch [87/100], Loss: 0.0251\n",
      "Epoch [88/100], Loss: 0.0233\n",
      "Epoch [89/100], Loss: 0.0217\n",
      "Epoch [90/100], Loss: 0.0202\n",
      "Epoch [91/100], Loss: 0.0187\n",
      "Epoch [92/100], Loss: 0.0174\n",
      "Epoch [93/100], Loss: 0.0161\n",
      "Epoch [94/100], Loss: 0.0150\n",
      "Epoch [95/100], Loss: 0.0139\n",
      "Epoch [96/100], Loss: 0.0128\n",
      "Epoch [97/100], Loss: 0.0119\n",
      "Epoch [98/100], Loss: 0.0110\n",
      "Epoch [99/100], Loss: 0.0103\n",
      "Epoch [100/100], Loss: 0.0095\n",
      "Finished Training Trainset\n"
     ]
    }
   ],
   "source": [
    "avg_list_loss = train(model, optimizer, loss_fn, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39dc0c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x201806d6370>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss\n",
    "plt.plot(avg_list_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "fce1d45328fd8024ce515f0ae0f0a25e82c54d2a05344803a525f4d98aa6e669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
